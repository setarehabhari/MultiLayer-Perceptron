{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBLTSYJFda6s"
   },
   "source": [
    "# Problem\n",
    "In this report we will to create a MultiLayer Perceptron and train it using our train data. After the training part we have to predict our test data result and try to maximize our accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BRTdFkbjuqs"
   },
   "source": [
    "# MultiLayer Perceptron\n",
    "\n",
    "***model***\n",
    "\n",
    "In this code our model can support any number of layers and any number of neurons in the model. The calculations will just continue until no hidden layer is left. \n",
    "\n",
    "\n",
    "***initial***\n",
    "\n",
    "To initialize our model we have to create a weight matrix. The index of this matrix will be generated randomly but in a certain range.\n",
    "\n",
    "\n",
    "***train***\n",
    "\n",
    "To train our model we will repeat the training until the termination condition is met (which in this case is the number of iterations). For training our data we will perform forward propagation and backpropagation on all of our training samples to calculate the error and use that to change the weight matrix. This change will be calculated using the learning rate at the beginning of the algorithm.\n",
    "\n",
    "\n",
    "***predict***\n",
    "\n",
    "\n",
    "After training our model we will give it our test data and see what it will predict for each input and then compare it with the actual output we got to get accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iz93h0ycQiX7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random \n",
    "import math\n",
    "from numpy import  dot,exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "z89W5LtnV83W"
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "  \n",
    "  def __init__(self, layer_list, epoch, learning_rate):\n",
    "    self.model = layer_list\n",
    "    self.num_layer = len(layer_list)\n",
    "    self.epoch = epoch\n",
    "    self.learning_rate = learning_rate\n",
    "    self.X_train, self.Y_train = self.read_file(\"train\")\n",
    "    self.X_test, self.Y_test = self.read_file(\"test\")\n",
    "    self.weight = [] \n",
    "\n",
    "  def read_file(self, file_name):\n",
    "    f = open(file_name, \"r\")\n",
    "    txt  = f.readlines()\n",
    "    X = []\n",
    "    Y  = []\n",
    "    for i in range(len(txt)):\n",
    "      params = [float(j) for j in txt[i].split()]\n",
    "      X.append([params[0], params[1]])\n",
    "      Y.append(params[2])\n",
    "    return X, Y\n",
    "\n",
    "  def activation(self, x):\n",
    "    return (1.0 - np.exp(-2*x))/(1.0 + np.exp(-2*x))\n",
    "\n",
    "  def activation_der(self, x):\n",
    "    return (1 + self.activation(x))*(1 - self.activation(x))\n",
    "\n",
    "  def calculate_weight(self):\n",
    "    np.random.seed(0)\n",
    "    for i in range(self.num_layer-1):\n",
    "      self.weight.append(\n",
    "       2*np.random.rand(self.model[i] + 1, self.model[i+1]) -1   \n",
    "      )\n",
    "\n",
    "  def MLPerceptron(self, x, expected_y):\n",
    "    result = x\n",
    "    for i in range(len(self.weight)-1):\n",
    "      dot_ans = np.dot(result[i], self.weight[i])\n",
    "      result.append(\n",
    "          np.concatenate((np.ones(1), np.array(self.activation(dot_ans))))\n",
    "      )\n",
    "    last_layer = self.activation(np.dot(result[-1], self.weight[-1]))\n",
    "    result.append(last_layer)\n",
    "\n",
    "    error = expected_y - result[-1]\n",
    "    weight_change = [error * self.activation_der(result[-1])]\n",
    "\n",
    "    for i in range(self.num_layer-2, 0 , -1):\n",
    "      error = weight_change[-1].dot(self.weight[i][1:].T)\n",
    "      error = error*self.activation_der(result[i][1:])\n",
    "      weight_change.append(error)\n",
    "\n",
    "    weight_change.reverse()\n",
    "\n",
    "    for i in range(len(self.weight)):\n",
    "      layer = result[i].reshape(1, self.model[i]+1)\n",
    "      self.weight[i] = self.weight[i] + self.learning_rate*layer.T.dot(weight_change[i].reshape(1, self.model[i+1]))\n",
    "  \n",
    "  def train_model(self):\n",
    "    bias = np.ones((1, self.X_train.shape[0]))\n",
    "    input = np.concatenate((bias.T, self.X_train), axis=1)\n",
    "\n",
    "    for i in range(self.epoch):\n",
    "      for i in range(len(self.X_train)):\n",
    "        self.MLPerceptron(\n",
    "            x = [input[i]],\n",
    "            expected_y = self.Y_train[i]\n",
    "        )\n",
    "  \n",
    "  def predict(self, x):\n",
    "    x_w_bias = np.concatenate((np.ones(1).T, np.array(x)))\n",
    "    for i in range(len(self.weight)):\n",
    "      res = self.activation(np.dot(x_w_bias, self.weight[i]))\n",
    "      x_w_bias = np.concatenate((np.ones(1).T, np.array(res)))\n",
    "    return x_w_bias[1]\n",
    "\n",
    "  def test_model(self):\n",
    "    predicted_result = []\n",
    "    for test in self.X_test:\n",
    "        p = self.predict(test)\n",
    "        if p >0.5:\n",
    "            predicted_result.append(1)\n",
    "        else:\n",
    "            predicted_result.append(0)\n",
    "    accuracy = 0\n",
    "    for i in range(len(predicted_result)):\n",
    "      if predicted_result[i] == self.Y_test[i]:\n",
    "        accuracy += 1\n",
    "    print(accuracy/len(predicted_result))\n",
    "\n",
    "  def start_MLP(self):\n",
    "    self.calculate_weight()\n",
    "    self.X_train = np.array(self.X_train)\n",
    "    self.Y_train = np.array(self.Y_train)\n",
    "    self.train_model()\n",
    "    self.test_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri15ZyZZ4GzK"
   },
   "source": [
    "# Parameters\n",
    "\n",
    "***learning rate***\n",
    "\n",
    "Learning rate will determine how fast our parameters will change as in how fast we will move towards our prediction. I found out that if we raise the amount of learning rate it will cause our accuracy to be much less. So I tried lowering it but not too much.\n",
    "\n",
    "***Layers***\n",
    "\n",
    "I found out that increasing the number of hidden layers will result in a better outcome but after 2 layers there wasn't much change. And increasing the number of layers didn't cause that much of a difference, only decreased the speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Dqu_giBIy_5"
   },
   "source": [
    "# Test Cases\n",
    "Finally we will run or mlp with the given train and test data and also print the test cases that our network predicted wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwgmDq_-GgNS",
    "outputId": "a6d5ea2a-2f6c-4936-edbd-28e4e3768d12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.938\n",
      "[[-0.633687809518789, 0.469846539860649], [0.020529179999515, -0.741064312936821], [0.230474265066374, 1.32188830412696], [0.208502349528497, -1.50069896375079], [0.504925712957714, 1.33289141417598], [-0.025901124087941, -0.637463169792611], [-0.182554291108849, -0.591716871650174], [-0.299854678639638, 0.081549971845352], [-0.748389402883773, -0.519726810513816], [-0.180832995475311, -1.37166912426394], [1.00480338161153, -2.24461117748409], [-0.287569052828006, 0.104110966761412], [0.22535723175402, -1.73359793273308], [-0.842592943376905, -1.40771658085872], [-0.267573699467927, -1.60862593686852], [0.523300924134902, -1.22786948924675], [0.403799434702408, -1.22460591754875], [0.028905774508546, -0.723527073613366], [0.959271009910824, -2.68560885690102], [0.087625271852143, -1.15046630113484], [0.339420145067856, -1.93150784958821], [0.244887479201154, -1.5344014704552], [0.627082730555767, -1.52627999732123], [-1.38032855874806, -0.501020857904726], [0.314398238897843, -1.16014834489779], [-0.054660028790205, -0.817716556338169], [-0.366880132683892, 0.464805374917938], [0.349588231390292, -0.530020989293143], [0.459601935637973, -1.17800048880264], [-0.505300538859998, 0.185478543450964], [-0.345823497280509, 1.45474119736962], [0.013138290934711, -0.986353136619641], [0.258174188974907, -0.580048364942101], [-0.035052916403317, -0.244040625126808], [-0.095021450832459, -1.13767391493268], [0.166966646807328, -0.200905536461674], [1.47196233077776, -0.867504204781095], [-0.038696093320545, -1.8207771025633], [0.119736598443221, -0.053013863927198], [0.426303697409958, -1.43153846639376], [0.663960821546651, -2.08258177380167], [0.172348642694422, -3.06977631344144], [-0.737875761782846, -0.370980028414214], [-0.614907168801596, -0.744195069628493], [-0.695016250295675, -0.878230560647033], [0.196811883889467, -1.48146296725201], [-0.838963169871462, 1.8599902623823], [-0.145006908157077, 0.11465406981449], [-0.615473710949184, -0.90939480381031], [0.083231915990881, -1.13821337602539], [-0.791026064125818, -1.45978524871262], [0.82844215041097, -1.77990153141609], [0.078585127121018, 0.24185496171936], [-0.234147373763754, -0.35777408912334], [-0.285443068054445, -0.128855091974938], [-0.339426995338057, -0.867804208821041], [1.33726700946565, -1.5841345527435], [0.498186186779213, -1.54366599380296], [0.359236888157046, -1.47072800221201], [-0.064580463633355, -0.016544199312989], [-0.587713279562207, -0.917138591852879], [-0.237249985639707, 0.03265177891414]]\n"
     ]
    }
   ],
   "source": [
    "instance = MLP([2,2,2,1], 1000, 0.001)\n",
    "instance.start_MLP()\n",
    "print(instance.wrong_results)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bio-hw6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
